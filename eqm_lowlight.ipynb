{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48860e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv_block(i, o):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(i, o, 3, padding=1),\n",
    "                nn.BatchNorm2d(o),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(o, o, 3, padding=1),\n",
    "                nn.BatchNorm2d(o),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.down1 = conv_block(in_channels, 64)\n",
    "        self.down2 = conv_block(64, 128)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = conv_block(128, 256)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.up2 = conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.up1 = conv_block(128, 64) \n",
    "\n",
    "    \n",
    "        self.out = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        x1 = self.down1(x) \n",
    "        x_pooled1 = self.pool(x1) \n",
    "        x2 = self.down2(x_pooled1) \n",
    "        x_pooled2 = self.pool(x2) \n",
    "\n",
    "        x_mid = self.bottleneck(x_pooled2) \n",
    "\n",
    "    \n",
    "        x_up2 = self.upconv2(x_mid) \n",
    "        x = torch.cat([x_up2, x2], dim=1) \n",
    "        x = self.up2(x)  \n",
    "\n",
    "        x_up1 = self.upconv1(x) \n",
    "        x = torch.cat([x_up1, x1], dim=1) \n",
    "        x = self.up1(x)\n",
    "\n",
    "       \n",
    "        return self.out(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336fc47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleUNet().to(device)\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "dummy_input = torch.randn(2, 3, 32, 32).to(device)\n",
    "output_shape = model(dummy_input).shape\n",
    "print(f\"Test output shape: {output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_gamma_truncated(gamma, a=0.8, lambda_mult=4.0):\n",
    "\n",
    "    a_tensor = torch.tensor(a, device=gamma.device)\n",
    "\n",
    "    c = torch.where(\n",
    "        gamma <= a_tensor,\n",
    "        torch.tensor(1.0, device=gamma.device),\n",
    "        (1.0 - gamma) / (1.0 - a)\n",
    "    )\n",
    "    return lambda_mult * c\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "\n",
    "def enhance_image(model, x_dark, num_steps=50, eta=0.1):\n",
    "\n",
    "    model.eval()\n",
    "    x_k = x_dark.clone()\n",
    "\n",
    "    history = [x_k.cpu()]\n",
    "\n",
    "    for k in range(num_steps):\n",
    "\n",
    "        pred_grad = model(x_k)\n",
    "\n",
    "        x_k = x_k - eta * pred_grad\n",
    "\n",
    "        if (k + 1) % 5 == 0:\n",
    "            history.append(x_k.cpu())\n",
    "\n",
    "    x_enhanced = x_k.clamp(0.0, 1.0)\n",
    "    history.append(x_enhanced.cpu())\n",
    "\n",
    "    return x_enhanced, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac954dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"soumikrakshit/lol-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LOW_DIR = os.path.join(path, 'lol_dataset/our485/low')\n",
    "TRAIN_HIGH_DIR = os.path.join(path, 'lol_dataset/our485/high')\n",
    "TEST_LOW_DIR = os.path.join(path, 'lol_dataset/eval15/low')\n",
    "TEST_HIGH_DIR = os.path.join(path, 'lol_dataset/eval15/high')\n",
    "\n",
    "print(f\"Train low dir exists: {os.path.exists(TRAIN_LOW_DIR)}\")\n",
    "print(f\"Train high dir exists: {os.path.exists(TRAIN_HIGH_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc595138",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 128\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(PATCH_SIZE),\n",
    "    transforms.RandomCrop(PATCH_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(PATCH_SIZE),\n",
    "    transforms.CenterCrop(PATCH_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, low_dir, high_dir, transform=None):\n",
    "        self.low_dir = low_dir\n",
    "        self.high_dir = high_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.low_images = sorted(os.listdir(low_dir))\n",
    "        self.high_images = sorted(os.listdir(high_dir))\n",
    "\n",
    "        assert len(self.low_images) == len(self.high_images), \"Mismatch in image counts\"\n",
    "        print(f\"Found {len(self.low_images)} paired images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low_img_path = os.path.join(self.low_dir, self.low_images[idx])\n",
    "        high_img_path = os.path.join(self.high_dir, self.high_images[idx])\n",
    "\n",
    "        low_img = Image.open(low_img_path).convert(\"RGB\")\n",
    "        high_img = Image.open(high_img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            seed = torch.randint(0, 2**32, (1,)).item()\n",
    "\n",
    "            torch.manual_seed(seed)\n",
    "            x_dark = self.transform(low_img)\n",
    "\n",
    "            torch.manual_seed(seed)\n",
    "            x_light = self.transform(high_img)\n",
    "\n",
    "        return x_light, x_dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairedImageDataset(TRAIN_LOW_DIR, TRAIN_HIGH_DIR, transform=train_transform)\n",
    "test_dataset = PairedImageDataset(TEST_LOW_DIR, TEST_HIGH_DIR, transform=test_transform)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created. Training on {len(train_dataset)} images.\")\n",
    "print(f\"Testing on {len(test_dataset)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleUNet().to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eqm_loss(model, x_light, x_dark):\n",
    "\n",
    "    B = x_light.shape[0]\n",
    "    dev = x_light.device\n",
    "\n",
    "\n",
    "    gamma = torch.rand(B, 1, 1, 1, device=dev)\n",
    "\n",
    "    x_gamma = gamma * x_light + (1.0 - gamma) * x_dark\n",
    "\n",
    "    target_direction = x_dark - x_light\n",
    "\n",
    "    c = c_gamma_truncated(gamma)\n",
    "\n",
    "    target = target_direction * c\n",
    "\n",
    "    pred_grad = model(x_gamma)\n",
    "\n",
    "    loss = criterion(pred_grad, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (x_light, x_dark) in enumerate(train_loader):\n",
    "\n",
    "        x_light = x_light.to(device)\n",
    "        x_dark = x_dark.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        loss = calculate_eqm_loss(model, x_light, x_dark)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"  [Epoch {epoch+1:02d}/{NUM_EPOCHS}, Batch {batch_idx:03d}/{len(train_loader)}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"===> Epoch {epoch+1} Complete: Avg. Loss: {avg_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prep_for_plot(tensor):\n",
    "    return tensor.cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "\n",
    "def plot_results(x_dark, x_enhanced, x_light):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    axes[0].imshow(prep_for_plot(x_dark))\n",
    "    axes[0].set_title(\"Input (Dark)\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(prep_for_plot(x_enhanced))\n",
    "    axes[1].set_title(\"Output (Enhanced)\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(prep_for_plot(x_light))\n",
    "    axes[2].set_title(\"Ground Truth (Light)\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_history(history):\n",
    "    num_images = len(history)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 3, 3))\n",
    "\n",
    "    for i, img in enumerate(history):\n",
    "        axes[i].imshow(prep_for_plot(img.squeeze(0)))\n",
    "        axes[i].set_title(f\"Step {i * 5 if i > 0 else 0}\")\n",
    "        axes[i].axis('off')\n",
    "    axes[-1].set_title(\"Final\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_PATH = \"EqM_Enhancer_LOL_v1.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x_light_test_batch, x_dark_test_batch = next(iter(test_loader))\n",
    "\n",
    "\n",
    "x_light_test_batch = x_light_test_batch.to(device)\n",
    "x_dark_test_batch = x_dark_test_batch.to(device)\n",
    "\n",
    "\n",
    "print(\"\\n--- Test Image 1 ---\")\n",
    "test_idx = 7\n",
    "x_d = x_dark_test_batch[test_idx].unsqueeze(0)\n",
    "x_l = x_light_test_batch[test_idx]\n",
    "\n",
    "x_e, history = enhance_image(model, x_d, num_steps=30, eta=0.01)\n",
    "\n",
    "\n",
    "plot_results(x_d.squeeze(0), x_e.squeeze(0), x_l)\n",
    "plot_history(history)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Test Image 2 ---\")\n",
    "test_idx = 10\n",
    "x_d = x_dark_test_batch[test_idx].unsqueeze(0)\n",
    "x_l = x_light_test_batch[test_idx]\n",
    "x_e, history = enhance_image(model, x_d, num_steps=30, eta=0.01)\n",
    "plot_results(x_d.squeeze(0), x_e.squeeze(0), x_l)\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
