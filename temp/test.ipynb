{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def reverse_step_gradients_corrected(s_v, s_h, x_v_next, x_h_next):\n",
    "    \"\"\"\n",
    "    Compute gradients according to equations (10-11) in the paper.\n",
    "    \"\"\"\n",
    "    # Visible–hidden couplings (Nv x Nh)\n",
    "    # First term: s_v[i] * x_h_next[j]\n",
    "    # Second term: s_h[j] * x_v_next[i]\n",
    "    grad_Jvh = torch.outer(s_v, x_h_next) + torch.outer(x_v_next, s_h)\n",
    "    \n",
    "    # Hidden–hidden couplings (Nh x Nh) - symmetric\n",
    "    outer_prod = torch.outer(s_h, x_h_next)\n",
    "    grad_Jhh = 0.5 * (outer_prod + outer_prod.T)\n",
    "    \n",
    "    # Hidden biases \n",
    "    grad_bh = s_h.clone()\n",
    "    \n",
    "    return grad_Jvh, grad_Jhh, grad_bh\n",
    "\n",
    "\n",
    "def train_model_improved(\n",
    "    mnist_dataset,\n",
    "    J_vh, J_hh, b_h,\n",
    "    num_epochs=5,\n",
    "    digits_per_epoch=10,\n",
    "    samples_per_digit=3,\n",
    "    dt=1e-3,\n",
    "    tf_train=2.5,\n",
    "    lr=1e-2,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Improved training function following the paper more closely.\n",
    "    \"\"\"\n",
    "    # Use multiple different digits as in the paper\n",
    "    training_digits = [0, 1, 7]  # Paper uses 3 digits\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        gradient_count = 0\n",
    "        \n",
    "        print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n",
    "        \n",
    "        # Accumulate gradients over multiple trajectories\n",
    "        grad_Jvh_epoch = torch.zeros_like(J_vh)\n",
    "        grad_Jhh_epoch = torch.zeros_like(J_hh)\n",
    "        grad_bh_epoch = torch.zeros_like(b_h)\n",
    "        \n",
    "        for _ in range(digits_per_epoch):\n",
    "            # Sample a random digit from training set\n",
    "            digit = random.choice(training_digits)\n",
    "            P = sample_digit_from_mnist(mnist_dataset, digit, device)\n",
    "            \n",
    "            for _ in range(samples_per_digit):\n",
    "                # Run noising trajectory\n",
    "                states_all, _ = run_noising_trajectory_improved(\n",
    "                    P, J_vh, J_hh, b_h, U, tf=tf_train, dt=dt, \n",
    "                    t_eq=0.5, bias_scale=20.0, device=device\n",
    "                )\n",
    "                \n",
    "                # Compute gradients over trajectory\n",
    "                num_steps = len(states_all) - 1\n",
    "                for (x_v, x_h), (x_v_next, x_h_next) in zip(states_all[:-1], states_all[1:]):\n",
    "                    nll, (s_v, s_h), _ = reverse_step_nll(\n",
    "                        x_v, x_h, x_v_next, x_h_next,\n",
    "                        J_vh, J_hh, b_h, dt, mu=1.0, kBT=1.0\n",
    "                    )\n",
    "                    \n",
    "                    dJvh, dJhh, dbh = reverse_step_gradients_corrected(s_v, s_h, x_v_next, x_h_next)\n",
    "                    \n",
    "                    grad_Jvh_epoch += dJvh\n",
    "                    grad_Jhh_epoch += dJhh\n",
    "                    grad_bh_epoch += dbh\n",
    "                    gradient_count += 1\n",
    "                    \n",
    "                    epoch_loss += nll.item()\n",
    "        \n",
    "        # Average gradients\n",
    "        grad_Jvh_epoch /= gradient_count\n",
    "        grad_Jhh_epoch /= gradient_count\n",
    "        grad_bh_epoch /= gradient_count\n",
    "        \n",
    "        # Update parameters\n",
    "        J_vh -= lr * grad_Jvh_epoch\n",
    "        J_hh -= lr * grad_Jhh_epoch\n",
    "        b_h -= lr * grad_bh_epoch\n",
    "        \n",
    "        # Optionally add gradient clipping\n",
    "        max_grad_norm = 10.0\n",
    "        torch.nn.utils.clip_grad_norm_([J_vh, J_hh, b_h], max_grad_norm)\n",
    "        \n",
    "        avg_loss = epoch_loss / gradient_count\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Avg NLL: {avg_loss:.4f}\")\n",
    "        print(f\"Parameter norms - J_vh: {J_vh.norm():.4f}, J_hh: {J_hh.norm():.4f}, b_h: {b_h.norm():.4f}\")\n",
    "    \n",
    "    return J_vh, J_hh, b_h, losses\n",
    "\n",
    "\n",
    "def run_noising_trajectory_improved(\n",
    "    P, J_vh, J_hh, b_h, U,\n",
    "    tf=2.5, dt=1e-3, t_eq=0.5,\n",
    "    bias_scale=20.0, device='cpu',\n",
    "    use_trainable=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Improved noising trajectory with proper coupling handling.\n",
    "    \"\"\"\n",
    "    K = int(tf / dt)\n",
    "    K_eq = int(t_eq / dt)\n",
    "    \n",
    "    # Initialize with noise\n",
    "    x_v = torch.randn(P.shape[0], device=device)\n",
    "    x_h = torch.randn(U.shape[0], device=device)\n",
    "    \n",
    "    # During noising, we DON'T use trainable couplings\n",
    "    if use_trainable:\n",
    "        Jvh_use, Jhh_use, bh_use = J_vh, J_hh, b_h\n",
    "    else:\n",
    "        Jvh_use = torch.zeros_like(J_vh)\n",
    "        Jhh_use = torch.zeros_like(J_hh)\n",
    "        bh_use = torch.zeros_like(b_h)\n",
    "    \n",
    "    states_all = []\n",
    "    \n",
    "    # Equilibration phase with full bias\n",
    "    for _ in range(K_eq):\n",
    "        b_v = P * bias_scale\n",
    "        b_h_eq = (U @ P) * bias_scale\n",
    "        x_v, x_h, _ = euler_maruyama_step(\n",
    "            x_v, x_h, b_v, b_h_eq, Jvh_use, Jhh_use, dt\n",
    "        )\n",
    "    \n",
    "    states_all.append((x_v.clone(), x_h.clone()))\n",
    "    \n",
    "    # Noising phase with fading bias\n",
    "    for k in range(K):\n",
    "        fade = 1.0 - (k / K)  # Linear fade from 1 to 0\n",
    "        b_v = P * bias_scale * fade\n",
    "        b_h_noise = (U @ P) * bias_scale * fade\n",
    "        \n",
    "        x_v, x_h, _ = euler_maruyama_step(\n",
    "            x_v, x_h, b_v, b_h_noise, Jvh_use, Jhh_use, dt\n",
    "        )\n",
    "        \n",
    "        states_all.append((x_v.clone(), x_h.clone()))\n",
    "    \n",
    "    return states_all, None\n",
    "\n",
    "\n",
    "def sample_digit_from_mnist(mnist, digit, device='cpu'):\n",
    "    \"\"\"Helper to sample a specific digit from MNIST dataset.\"\"\"\n",
    "    idxs = [i for i, (_, y) in enumerate(mnist) if y == digit]\n",
    "    i = random.choice(idxs)     \n",
    "    v, _ = mnist[i]\n",
    "    return v.view(-1).to(device)\n",
    "\n",
    "\n",
    "def euler_maruyama_step(x_v, x_h, b_v, b_h, J_vh, J_hh, dt, kBT=1.0, mu=1.0):\n",
    "    \"\"\"Euler-Maruyama integration step (unchanged from original).\"\"\"\n",
    "    # Compute energy and gradients\n",
    "    V, g_v, g_h = energy_and_grad(x_v, x_h, b_v, b_h, J_vh, J_hh)\n",
    "    \n",
    "    # Gaussian noise\n",
    "    noise_v = torch.randn_like(x_v)\n",
    "    noise_h = torch.randn_like(x_h)\n",
    "    \n",
    "    sigma = torch.sqrt(torch.tensor(2.0 * mu * kBT * dt, device=x_v.device, dtype=x_v.dtype))\n",
    "    \n",
    "    # Update positions\n",
    "    x_vn = x_v - mu * g_v * dt + sigma * noise_v\n",
    "    x_hn = x_h - mu * g_h * dt + sigma * noise_h\n",
    "    \n",
    "    return x_vn, x_hn, V\n",
    "\n",
    "\n",
    "def energy_and_grad(x_v, x_h, b_v, b_h, J_vh, J_hh, J2=10.0, J4=10.0):\n",
    "    \"\"\"Compute energy and its gradient (unchanged from original).\"\"\"\n",
    "    b_v = b_v.to(x_v.device)\n",
    "    b_h = b_h.to(x_h.device)\n",
    "    \n",
    "    x_v = x_v.clone().detach().requires_grad_(True)\n",
    "    x_h = x_h.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Energy terms\n",
    "    V = J2*(x_v.pow(2).sum() + x_h.pow(2).sum()) \\\n",
    "      + J4*(x_v.pow(4).sum() + x_h.pow(4).sum()) \n",
    "    V = V + (b_v @ x_v) + (b_h @ x_h) \n",
    "    V = V + (x_v @ J_vh @ x_h) + 0.5*(x_h @ J_hh @ x_h)\n",
    "    \n",
    "    V.backward()\n",
    "    \n",
    "    g_v = x_v.grad.detach()\n",
    "    g_h = x_h.grad.detach()\n",
    "    \n",
    "    return V.item(), g_v, g_h\n",
    "\n",
    "\n",
    "def reverse_step_nll(\n",
    "    x_v, x_h, x_v_next, x_h_next,\n",
    "    J_vh, J_hh, b_h, dt,\n",
    "    mu=1.0, kBT=1.0, J2=10.0, J4=10.0\n",
    "):\n",
    "    \"\"\"Compute negative log-likelihood of reverse step (unchanged).\"\"\"\n",
    "    b_v_trainable = torch.zeros_like(x_v_next)\n",
    "    _, g_v_next, g_h_next = energy_and_grad(\n",
    "        x_v_next, x_h_next, b_v_trainable, b_h, J_vh, J_hh, J2, J4\n",
    "    )\n",
    "    \n",
    "    dx_v = x_v_next - x_v\n",
    "    dx_h = x_h_next - x_h\n",
    "    \n",
    "    r_v = -dx_v + mu * g_v_next * dt\n",
    "    r_h = -dx_h + mu * g_h_next * dt\n",
    "    \n",
    "    denominator = 4.0 * mu * kBT * dt\n",
    "    nll = (r_v.pow(2).sum() + r_h.pow(2).sum()) / denominator\n",
    "    \n",
    "    s_v = r_v / (2.0 * kBT)\n",
    "    s_h = r_h / (2.0 * kBT)\n",
    "    \n",
    "    return nll, (s_v, s_h), (x_v_next, x_h_next)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y4project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
