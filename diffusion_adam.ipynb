{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50da1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca56422",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype  = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbce1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1)),  # flatten 28x28 → 784\n",
    "    transforms.Lambda(lambda v: (v - v.mean()) / (v.std() + 1e-8))\n",
    "])\n",
    "\n",
    "mnist = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "\n",
    "def sample_digit(digit, device=\"cpu\"):\n",
    "    \n",
    "    idxs = [i for i, (_, y) in enumerate(mnist) if y == digit]\n",
    "    i = random.choice(idxs)     \n",
    "    v, y = mnist[i]\n",
    "    return v.view(-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd26e915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_digit(7).view(28,28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "kBT = 1.0\n",
    "mu = 1.0\n",
    "J2 = 10.0\n",
    "J4 = 10.0\n",
    "\n",
    "# Chosen through trial and error\n",
    "bias_scale = 20.0\n",
    "\n",
    "Nv = 28*28  # number of visible units\n",
    "Nh = 512     # number of hidden units\n",
    "\n",
    "J_vh = torch.zeros(Nv, Nh, device=device)   # visible-to-hidden couplings\n",
    "J_hh = torch.zeros(Nh, Nh, device=device)   # hidden-to-hidden couplings\n",
    "b_h  = torch.zeros(Nh, device=device)       # hidden biases\n",
    "# no visible-to-visible couplings\n",
    "\n",
    "def energy_and_grad(x_v, x_h, b_v, b_h, J_vh, J_hh):\n",
    "  \n",
    "    b_v = b_v.to(x_v.device)\n",
    "    b_h = b_h.to(x_h.device)\n",
    "    \n",
    "    # Compute V_theta(x) and its gradients (autograd)\n",
    "    x_v = x_v.clone().detach().requires_grad_(True)\n",
    "    x_h = x_h.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Energy terms\n",
    "    V = J2*(x_v.pow(2).sum() + x_h.pow(2).sum()) \\\n",
    "      + J4*(x_v.pow(4).sum() + x_h.pow(4).sum()) \n",
    "    V = V + (b_v @ x_v) + (b_h @ x_h) \n",
    "    V = V + (x_v @ J_vh @ x_h) + 0.5*(x_h @ J_hh @ x_h)\n",
    "    \n",
    "    V.backward()\n",
    "\n",
    "    g_v = x_v.grad.detach()\n",
    "    g_h = x_h.grad.detach()\n",
    "\n",
    "    return V.item(), g_v, g_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da6bcf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_maruyama_step(x_v, x_h, b_v, b_h, J_vh, J_hh, dt, kBT=1.0, mu=1.0):\n",
    "    \n",
    "    # Compute energy and gradients\n",
    "    V, g_v, g_h = energy_and_grad(x_v, x_h, b_v, b_h, J_vh, J_hh)\n",
    "    \n",
    "    # Gaussian noise\n",
    "    noise_v = torch.randn_like(x_v)\n",
    "    noise_h = torch.randn_like(x_h)\n",
    "    \n",
    "    sigma = torch.sqrt(torch.tensor(2.0 * mu * kBT * dt, device=x_v.device, dtype=x_v.dtype))\n",
    "\n",
    "    # Euler-Maruyama update\n",
    "    x_vn = x_v - mu * g_v * dt + sigma * noise_v\n",
    "    x_hn = x_h - mu * g_h * dt + sigma * noise_h\n",
    "    \n",
    "    return  x_vn, x_hn, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0619defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection (Random Projection) \n",
    "# TODO: try alternatives\n",
    "U = torch.randn(Nh, Nv, device=device) / math.sqrt(Nv)\n",
    "\n",
    "def fade_schedule(k: int, K: int) -> float:\n",
    "    \"\"\"Linear fade from 1 → 0 over K steps.\"\"\"\n",
    "    return 1.0 - (k / K)\n",
    "\n",
    "def visible_bias_schedule(P: torch.Tensor, k: int, K: int, scale=1.0) -> torch.Tensor:\n",
    "    return (scale * fade_schedule(k, K) * P).to(P.device)\n",
    "\n",
    "# Project visible bias onto hidden units\n",
    "def hidden_bias_schedule(P: torch.Tensor, k: int, K: int, scale=1.0) -> torch.Tensor:\n",
    "    return (scale * fade_schedule(k, K) * (U @ P)).to(P.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca475a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward noising trajectory\n",
    "\n",
    "def run_noising_trajectory(P, tf=2.5, dt=1e-3, snapshots=12, t_eq=0.5, use_trainable=False):\n",
    "    \n",
    "    K = int(tf / dt)\n",
    "    snap_every = max(1, K // snapshots)\n",
    "    \n",
    "    if use_trainable:\n",
    "        Jvh, Jhh = J_vh, J_hh   # trainable parameters\n",
    "    else:\n",
    "        Jvh = torch.zeros_like(J_vh)\n",
    "        Jhh = torch.zeros_like(J_hh)\n",
    "    \n",
    "    x_v = torch.randn(Nv, device=device)\n",
    "    x_h = torch.randn(Nh, device=device)\n",
    "\n",
    "    states_all = []\n",
    "    vis_snaps = []\n",
    "    \n",
    "    # Reach equilibrium\n",
    "    K_eq = int(t_eq / dt)\n",
    "    for _ in range(K_eq):\n",
    "        b_v = (P * bias_scale).to(P.device)\n",
    "        b_h = ((U @ P) * bias_scale).to(P.device)    \n",
    "        x_v, x_h, V = euler_maruyama_step(x_v, x_h, b_v, b_h, Jvh, Jhh, dt, kBT, mu)\n",
    "\n",
    "    states_all.append((x_v.clone(), x_h.clone()))\n",
    "    for k in range(K):\n",
    "        b_v = visible_bias_schedule(P, k, K, scale=bias_scale)\n",
    "        b_h = hidden_bias_schedule(P, k, K, scale=bias_scale)\n",
    "\n",
    "        x_v, x_h, V = euler_maruyama_step(x_v, x_h, b_v, b_h, Jvh, Jhh, dt, kBT, mu)\n",
    "\n",
    "        states_all.append((x_v.clone(), x_h.clone()))\n",
    "        \n",
    "        if k % snap_every == 0 or k == K - 1:\n",
    "            vis_snaps.append(x_v.clone())\n",
    "\n",
    "    return states_all, vis_snaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y4project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
